# -*- coding: utf-8 -*-
"""Credit card det

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1369-e7Javs9dZ7Dhhv7-WZn03Li5nRtO
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
print("Loading data...")
dev_data = pd.read_csv('Dev_data_to_be_shared.csv')

# Prepare features and target
print("Preparing features...")
X = dev_data.drop(['account_number', 'bad_flag'], axis=1)
y = dev_data['bad_flag']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

# Define and train the model
print("Training model...")
model = RandomForestClassifier(random_state=42)  #  model  defined
model.fit(X_train_scaled, y_train)

def normalize_probabilities(predictions):
    """
    Normalize predictions to ensure they're between 0 and 1
    """
    predictions_normalized = np.clip(predictions, 0, 1)
    print(f"Original predictions range: {predictions.min():.3f} to {predictions.max():.3f}")
    print(f"Normalized predictions range: {predictions_normalized.min():.3f} to {predictions_normalized.max():.3f}")
    return predictions_normalized

def run_sanity_checks(predictions):
    """
    Run basic sanity checks on predictions
    """
    checks_passed = True

    if not all((predictions >= 0) & (predictions <= 1)):
        print("ERROR: Not all predictions are between 0 and 1")
        checks_passed = False

    if np.any(np.isnan(predictions)):
        print("ERROR: Predictions contain NaN values")
        checks_passed = False

    if np.any(np.isinf(predictions)):
        print("ERROR: Predictions contain infinite values")
        checks_passed = False

    print("\nPrediction Distribution:")
    print(f"Mean: {predictions.mean():.3f}")
    print(f"Median: {np.median(predictions):.3f}")
    print(f"Std Dev: {predictions.std():.3f}")

    return checks_passed

def additional_checks(predictions):
    """
    Additional sanity checks for predictions
    """
    if predictions.mean() > 0.5:
        print("WARNING: Mean prediction is unusually high (>0.5)")

    extremes = np.sum((predictions < 0.01) | (predictions > 0.99))
    if extremes/len(predictions) > 0.1:
        print("WARNING: More than 10% of predictions are extreme values")

    if predictions.std() < 0.01:
        print("WARNING: Very low variation in predictions")

    return True

# Load validation data
print("Loading validation data...")
val_data = pd.read_csv('validation_data_to_be_shared.csv')
val_features = val_data.drop(['account_number'], axis=1)

# Process validation data
val_features_imputed = imputer.transform(val_features)
val_features_scaled = scaler.transform(val_features_imputed)

# Make predictions
print("Making predictions...")
val_predictions = model.predict_proba(val_features_scaled)[:, 1]

# Normalize predictions
val_predictions = normalize_probabilities(val_predictions)

# Run sanity checks
if run_sanity_checks(val_predictions) and additional_checks(val_predictions):
    print("\nAll sanity checks passed!")

    # Creating submission
    submission = pd.DataFrame({
        'account_number': val_data['account_number'],
        'predicted_probability': val_predictions
    })

    # Plot distribution
    plt.figure(figsize=(10, 6))
    sns.histplot(val_predictions, bins=50)
    plt.title('Distribution of Predicted Probabilities')
    plt.xlabel('Probability')
    plt.ylabel('Count')
    plt.show()

    submission.to_csv('credit_card_predictions.csv', index=False)
    print("Predictions saved to file!")
else:
    print("\nWARNING: Sanity checks failed! Please review the predictions.")

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_feature_importance(X_train, y_train, feature_names):
    # Ensure feature_names length matches X_train columns
    if len(feature_names) != X_train.shape[1]:
        # Get indices of columns that were dropped during imputation
        print("Adjusting feature names to match data...")
        # Drop the features that were skipped during imputation
        feature_names = feature_names.copy()
        feature_names = [f for f in feature_names if f not in ['bureau_436', 'bureau_447']]

    # Create and train Random Forest model
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_train, y_train)

    # Create importance dataframe
    importances = pd.DataFrame({
        'Feature': feature_names,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)

    # Plot
    plt.figure(figsize=(12, 6))
    sns.barplot(x='Importance', y='Feature', data=importances.head(15))
    plt.title('Top 15 Most Important Features')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    return importances

# ===Main code===
print("Loading data...")
dev_data = pd.read_csv('Dev_data_to_be_shared.csv')

# Remove any rows with NaN in target variable
dev_data = dev_data.dropna(subset=['bad_flag'])

# Prepare features and target
print("Preparing features...")
X = dev_data.drop(['account_number', 'bad_flag'], axis=1)
y = dev_data['bad_flag']

# Store feature names before any processing
feature_names = X.columns.tolist()

# Split the data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Remove columns with all NaN values before imputation
X_train = X_train.drop(['bureau_436', 'bureau_447'], axis=1)
X_test = X_test.drop(['bureau_436', 'bureau_447'], axis=1)

# Handle missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Scale features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

# Update feature names to match actual features used
feature_names = [f for f in feature_names if f not in ['bureau_436', 'bureau_447']]

print("\nAnalyzing feature importance...")
try:
    importances = analyze_feature_importance(X_train_scaled, y_train, feature_names)

    # Print top 10 most important features
    print("\nTop 10 Most Important Features:")
    print(importances.head(10))

    # Save results
    importances.to_csv('feature_importance.csv', index=False)
    print("\nResults saved to 'feature_importance.csv'")

except Exception as e:
    print(f"An error occurred: {e}")

print("\nAnalysis complete!")

def analyze_data_quality(data):
    """
    Analyze missing values and outliers in the dataset
    """
    print("\n=== DATA QUALITY ANALYSIS ===")

    # Missing Values Analysis
    print("\n1. MISSING VALUES:")
    missing = pd.DataFrame({
        'Feature': data.columns,
        'Missing_Count': data.isnull().sum(),
        'Missing_Percentage': np.round((data.isnull().sum() / len(data) * 100), 2)  # Fixed the round issue
    }).sort_values('Missing_Percentage', ascending=False)

    # Show only features with missing values
    missing_features = missing[missing['Missing_Count'] > 0]
    if len(missing_features) > 0:
        print("\nFeatures with missing values:")
        print(missing_features)
    else:
        print("No missing values found.")

    # Outlier Analysis
    print("\n2. OUTLIERS:")
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    outlier_summary = []

    for col in numeric_cols:
        try:
            # Calculate quartiles and IQR
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1

            # Define bounds
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            # Count outliers
            outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)][col]

            if len(outliers) > 0:
                outlier_summary.append({
                    'Feature': col,
                    'Outlier_Count': len(outliers),
                    'Outlier_Percentage': np.round((len(outliers) / len(data) * 100), 2),  # Fixed the round issue
                    'Min': np.round(data[col].min(), 2),
                    'Max': np.round(data[col].max(), 2)
                })
        except Exception as e:
            print(f"Skipping column {col} due to error: {e}")
            continue

    if outlier_summary:
        outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier_Percentage', ascending=False)
        print("\nTop 10 Features with Most Outliers:")
        print(outlier_df.head(10))
    else:
        print("No outliers found.")

    return missing_features, pd.DataFrame(outlier_summary)


try:
    # Load data first
    print("Loading data...")
    dev_data = pd.read_csv('Dev_data_to_be_shared.csv')

    # Prepare features
    X = dev_data.drop(['account_number', 'bad_flag'], axis=1)

    print("Analyzing data quality...")
    missing_analysis, outlier_analysis = analyze_data_quality(X)

    # Saving analyses to CSV with better error handling
    if not missing_analysis.empty:
        missing_analysis.to_csv('missing_values_analysis.csv', index=False)
        print("\nMissing values analysis saved to 'missing_values_analysis.csv'")

    if not outlier_analysis.empty:
        outlier_analysis.to_csv('outlier_analysis.csv', index=False)
        print("Outlier analysis saved to 'outlier_analysis.csv'")

except Exception as e:
    print(f"Error in data quality analysis: {e}")

def plot_outliers(data, feature_names=None, max_features=5):
    """
    Plot outliers along with other data points
    """
    #  select numeric columns with most outliers
    if feature_names is None:
        numeric_cols = data.select_dtypes(include=[np.number]).columns
        outlier_counts = {}

        for col in numeric_cols:
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outlier_count = len(data[(data[col] < lower_bound) | (data[col] > upper_bound)])
            outlier_counts[col] = outlier_count

        # top features with most outliers
        feature_names = sorted(outlier_counts.items(), key=lambda x: x[1], reverse=True)[:max_features]
        feature_names = [f[0] for f in feature_names]

    # Creating subplots
    n_features = len(feature_names)
    fig, axes = plt.subplots(1, n_features, figsize=(5*n_features, 6))
    if n_features == 1:
        axes = [axes]

    for ax, feature in zip(axes, feature_names):
        # Calculating bounds
        Q1 = data[feature].quantile(0.25)
        Q3 = data[feature].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Separating normal points and outliers
        normal = data[(data[feature] >= lower_bound) & (data[feature] <= upper_bound)][feature]
        outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)][feature]

        # Create scatter plot
        ax.scatter(range(len(normal)), normal, c='blue', alpha=0.5, label='Normal', s=20)
        ax.scatter(range(len(normal), len(normal) + len(outliers)), outliers,
                  c='red', alpha=0.7, label='Outliers', s=30)

        ax.set_title(f'{feature}\n({len(outliers)} outliers)', fontsize=10)
        ax.set_xlabel('Data Points')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Print summary statistics
    print("\nOutlier Summary:")
    for feature in feature_names:
        Q1 = data[feature].quantile(0.25)
        Q3 = data[feature].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)][feature]

        print(f"\n{feature}:")
        print(f"Number of outliers: {len(outliers)}")
        print(f"Outlier percentage: {(len(outliers)/len(data)*100):.2f}%")
        print(f"Range: [{data[feature].min():.2f}, {data[feature].max():.2f}]")
        print(f"Normal range: [{lower_bound:.2f}, {upper_bound:.2f}]")


try:
    # After loading and preparing your data
    print("\nPlotting outliers...")

   
    plot_outliers(X)

    

except Exception as e:
    print(f"Error in plotting outliers: {e}")